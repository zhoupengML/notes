#+OPTIONS: tex:t
#+TITLE: 最优化
#+AUTHOR: Peng Zhou


* Chapter 1 凸集与凸函数

** 凸函数的判别

   1. 设$f:R^n\to{R}$ , 且二阶连续可微， 则下列命题等价

      1) $f$ 是凸函数

      2) 对 $\forall{x, y} \in{R^n}$ , 有 $f(y)\ge{f(x)+\nabla{f(x)^T}(y-x)}$

      3) 梯度函数 $\nabla{f(x)}$ 单调

	 $$[\nabla{f(y)}-\nabla{f(x)}]^T(y-x)\ge{0}$$

      4) $\forall{x}\in{R^n} , Hesse$ 矩阵 $\nabla^2{f(x)}$ 半正定 (正定矩阵: positive definite matrix)

   2. 定理[p20]:
      设 $S$ 是 $R^n$ 中非空开凸集, $f(x)$ 是定义在 $S$ 上的可微函数,则 $f(x)$ 为凸函数的充要条件是
      对任意两点 $x^{(1)},x^{(2)}\in{S}$ ,都有

      $f(x^{(2)})\ge{}f(x^{(1)})+\nabla{}f(x^{(1)})^T(x^{(2)}-x^{(1)})$

      而 $f(x)$ 为严格凸函数的充要条件是对任意的互不相同的 $x^{(1)},x^{(2)}\in{S}$ ,成立
      
      $f(x^{(2)})>f(x^{(1)})+\nabla{}f(x^{(1)})^T(x^{(2)}-x^{(1)})$

*** 正定二次型的定义 [[http://wenku.baidu.com/link?url=J912nnUKjFJYkRt-w89TPkotscm0SnFl4XwYXHSrxOEDau0TLibvB9J3K81hKOyH-B3K3JWS2_hE9lW6eFj7S1GhD8wDhOg7nqpU2QQ7oLO][ref]]

    * 定义
      在实二次型 $f(x_1,x_2,...,x_n)$ 中, 若对于任意一组不全为 $0$ 的实数 $c_1,c_2,...,c_n$ ,
      都有 $f(x_1,x_2,...,x_n)>0$ , 则称该二次型为正定的; 
      若 $f(x_1,x_2,...,x_n)\ge{0}$ , 则称 $f$ 为半正定二次型; 
      若 $f(x_1,x_2,...,x_n)<0$ , 则称 $f$ 为负定二次型; 
      若 $f(x_1,x_2,...,x_n)\le{0}$ , 则称 $f$ 为半负定二次型;
      若实二次型既不是半正定又不是半负定的则称为不定二次型.
      
*** 正定矩阵的定义 [[http://wenku.baidu.com/link?url=J912nnUKjFJYkRt-w89TPkotscm0SnFl4XwYXHSrxOEDau0TLibvB9J3K81hKOyH-B3K3JWS2_hE9lW6eFj7S1GhD8wDhOg7nqpU2QQ7oLO][ref]]

    * 定义
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 正定, 则称实对称矩阵 $A$ 正定;
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 半正定, 则称实对称矩阵 $A$ 半正定;
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 负定, 则称实对称矩阵 $A$ 负定;
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 半负定, 则称实对称矩阵 $A$ 半负定;
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 不定, 则称实对称矩阵 $A$ 不定.

*** 正定矩阵的判定

**** 正定矩阵判定定理

     1. $n$ 元实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 是正定的充要条件是:
	它的标准型的系数全为正.
	
	+ 用合同变换法化二次型为标准型 [[http://wenku.baidu.com/link?url=1M3RiheBvR4d7sHe1S4htMZzH902EgWo0APzOax7F5oREnwilnTwWQI-F0Els_uinKhevcOL9lPRQnM6-PFL34kUTC96jdC4bwwQRsMDsNS][ref]]

	  1) 写出二次型的矩阵 $A$

	  2) 作 $(A\ E)\xrightarrow[elementary\ row\ operation\ of\ E]{congruent\ transformation\ of\ A}(\land{\ P^T})$ , 求出 $P^T$

	  3) 作非退化的线性变换 $X=PY$ , 将二次型化为标准型
      
*** 矩阵的等价, 相似, 合同 [[http://wenku.baidu.com/link?url=QRehRaAsSmbyVxbYFkyJQRkXw5y-KmKN0eSoFwW7sU--566tbOd3m5NEtCHw8s6LEN4Y_RGH3nMugFTvABikDMFrcjf3ZbOQMVBNR9ZrFI_][ref]]

**** 矩阵等价的定义

     如果矩阵 $A$ 可以经过一系列初等变换变成 $B$ , 则 $A$ 与 $B$ 等价,
     记为 $A\cong{B}$ .

**** 矩阵相似的定义
     
     设 $A,B$ 是数域 $F$ 上的 $n$ 阶方阵, 如果存在数域 $F$ 上的 $n$ 阶
     可逆矩阵 $P$ , 使得 $B=P^{-1}AP$ , 则称 $A$ 与 $B$ 相似,
     记为 $A\sim{B}$ .

**** 矩阵合同的定义
     
     设 $A,B$ 是数域 $F$ 上的 $n$ 阶方阵, 如果存在数域 $F$ 上的 $n$ 阶
     可逆矩阵 $P$ , 使得 $P^{T}AP=B$ , 则称在数域 $F$ 上 $A$ 与 $B$ 合同.


*  Chapter 2 线性规划的基本性质

** 线性规划标准形式
   \begin{eqnarray}
    \min{}&\ &\sum_{j=1}^{n}{c_jx_j}\\
    s.t.\ \ \sum_{j=1}^{n}\alpha_{ij}x_j&=&b_i, i=1,...,m\nonumber\\
    x_j&\ge&{0}, j=1,...,n\nonumber
   \end{eqnarray}

矩阵形式:

   \begin{eqnarray}
    \label{eq:2}
    \min&{c^Tx}&\\
    s.t.\ \ Ax&=&b\nonumber\\
    x&\ge&{0}\nonumber
   \end{eqnarray}

**  可行域
    1. 在线性规划中,约束条件均为线性等式及不等式,满足这些条件的点的集合是凸集
    2. 线性规划的可行域是凸集

** 最优极点							    :Theorem:
   1.线性规划如果存在最优解,那么最优值一定能在某极点上达到

   2.设可行域的极点为 $x^{(1)},x^{(2)},...,x^{(k)}$, 极方向为 $d^{(1)},d^{(2)},...,d^{(l)}$, 根据定理[p12],
      任何可行点 $x$ 可以表示为

      \begin{eqnarray}
      x=\sum_{j=1}^k\lambda_jx^{(j)}&+&\sum_{j=1}^l\mu_jd^{(j)}\\
      \sum_{j=1}^k\lambda_j&=&1\nonumber\\
      \lambda_j&\ge&{0},\ j=1,...,k\nonumber\\
      \mu_j&\ge&0,\ j=1,...,l
      \end{eqnarray}

   - 定理2.2.2 设线性规划的可行域非空,则
     1) 线性规划存在有限最优解的充要条件是所有 $c^Td^{(j)}$  为非负数.
     2) 若线性规划存在有限最优解,则目标函数的最优值可在某个极点上达到.

**  最优基本可行解						    :Theorem:
    1. 对于线性规划,基本可行解与可行域的极点之间总存在着对应关系.
       
    2. 定理2.2.3 
       令 $K=\{x|Ax=b,x\ge{0}\},A$ 是 $m\times{n}$ 矩阵, $A$  的秩为 $m$, 则 $K$
        的极点集与 $Ax=b,x\ge{0}$ 的基本可行解集等价.

    3.  线性规划问题的求解,可归结为求最优基本可行解.

** 基本可行解的存在问题						    :Theorem:
   1. 定理1.4.1 [p12]
       若多面集 $S=\{x|Ax=b,x\ge{0}\}$ 非空,则存在有限个极点(有限个基本可行解).
   2. 定理2.2.4 [p34]
      如果 $Ax=b,x\ge{0}$  有可行解,则一定存在基本可行解.其中 $A$ 是 $m\times{n}$ 矩阵,
      $A$ 的秩为 $m$.

** Practice								:Def:
   1. 定义2.2.1 基本解 [p30]
      
      \begin{equation}
      x=\begin{bmatrix}x_B\\x_N\end{bmatrix}
      =\begin{bmatrix}B^{-1}b\\0\end{bmatrix}
      \end{equation}
      
       称为方程组 $Ax=b$  的一个基本解. 矩阵 $A$ 的秩为 $m$, $A=[B,N]$, $B$  是 $m$ 阶
       可逆矩阵.

* Chapter 3 单纯形方法

** 单纯形方法原理

*** 基本可行解的转换
    
    1. 若线性规划有最优解,则必存在最优基本可行解.
    2. 单纯形方法的基本思想,就是从一个基本可行解出发,求一个使目标函数值有所改善的基本可行解,通过
       不断改进基本可行解,力图达到最优基本可行解.
    3. 
        \begin{eqnarray}
	    \min\ f& \stackrel{def}{=}&cx\\
	    s.t.\ Ax&=&b\nonumber\\
	    x&\ge&0\nonumber
	\end{eqnarray}

       - $A_{m\times{n}}$ , $rank(A)=m$ ,$c$ : $n$ 维行向量, $x$ : $n$ 维列向量, $b\ge0$ 是 $m$ 维列向量.

       - 记 $$A=(p_1,p_2,...,p_n)$$

       - 将 $A$ 分解成 $(B,N)$ ,使得其中 $B$ 是基矩阵, $N$ 是非基矩阵,设 

	 \begin{eqnarray}
	 x^{(0)}=
         \begin{bmatrix}
	 B^{-1}b\\0
         \end{bmatrix}
         \end{eqnarray}

	 是基本可行解,在 $x^{(0)}$ 处的目标函数值
	 
	 \begin{eqnarray}
	 f_{0}=cx^{(0)}=(c_{B},c_{N})
	 \begin{bmatrix}B^{-1}b\\0 \end{bmatrix}
	 =c_BB^{-1}b
         \end{eqnarray}
	 
	 $c_B$ 是 $c$ 中与基变量对应的分量组成的 $m$ 维行向量. $c_N$ 是 $c$ 中与非基变量对应的分量组成的 $n-m$ 维行向量.

       - 现在分析怎么从基本可行解 $x^{(0)}$ 出发,求一个改进的基本可行解. 设 
	 
	 \begin{eqnarray}
	 x=
	 \begin{bmatrix}x_B\\x_N  \end{bmatrix}
	 \end{eqnarray}
	 
	 是任一个可行解,则由 $Ax=b$ 得到 $$x_{B}=B^{-1}b-B^{-1}Nx_N$$ ,在点 $x$ 处的目标函数值
	 
	 \begin{eqnarray}
	 \label{eq:1}
	 f&=&cx=(c_B,c_N)
	 \begin{bmatrix}x_B\\x_N    \end{bmatrix}\\
	 &=&c_Bx_B+c_Nx_N\nonumber\\
	 &=&c_B(B^{-1}b-B^{-1}Nx_N)+c_Nx_N\nonumber\\
	 &=&c_BB^{-1}b-(c_BB^{-1}N-c_N)x_N\nonumber\\
	 &=&f_0-\sum_{j\in{R}}(c_BB^{-1}p_j-c_j)x_j\nonumber\\
	 &=&f_0-\sum_{j\in{R}}(z_j-c_j)x_j\nonumber
         \end{eqnarray}
	 
	 其中 $R$ 是非基变量下标集
	 
	 $$z_j=c_BB^{-1}p_j$$
	 
	 由上式可知,适当选取自由未知量 $x_j(j\in{R})$ 的数值就有可能使得 
	 
	 \begin{equation} \sum_{j\in{R}}(z_j-c_j)x_j>0	 \end{equation}
	 
	 从而得到使目标函数值减少的新的基本可行解.为此,在原来的 $n-m$ 个非基变量中,使得 $n-m-1$ 个变量仍然取零值,
	 而另一个非基变量,比如 $x_k$ 增大,即取正值.怎样确定下标 $k$ 呢?当 $x_j(j\in{R})$ 取值相同时, $z_j-c_j$ (正数)越大,目标函数值
	 下降越多,因此选择 $x_k$, 使
	 
	 \begin{equation}z_k-c_k=\max_{j\in{R}}\{z_j-c_j\}    \end{equation}
	 
	 这里假设 $z_k-c_k>0$

       - $x_k$ 由零变为正数后,得到方程组 $Ax=b$ 的解
	 
	 \begin{eqnarray}x_B=B^{-1}b-B^{-1}p_kx_k=\stackrel{-}{b}-y_kx_k    \end{eqnarray}
    	 
	 其中 $\stackrel{-}{b}$ 和 $y_k$ 是 $m$ 维列向量, $\stackrel{-}{b}=B^{-1}b , y_k=B^{-1}p_k$ , 把 $x_B$ 按分量写出,即
	 
	 \begin{eqnarray}
	 x_B=
	 \begin{bmatrix}
	 x_{B_1}\\x_{B_2}\\\vdots\\x_{B_m}    \end{bmatrix}
	 = \begin{bmatrix}\stackrel{-}{b}_1\\\stackrel{-}{b}_2\\\vdots\\\stackrel{-}{b}_m    \end{bmatrix}
	 - \begin{bmatrix}y_{1k}\\y_{2k}\\\vdots\\y_{mk}    \end{bmatrix}
	 x_k
	 \end{eqnarray}
	 
	 $$x_N=(0,\ldots,0,x_k,0,\ldots,0)^T$$

       - 在新得到的点,目标函数值是
	 
	 $$f=f_0-(z_k-c_k)x_k$$

       - 再来分析 $x_k$ 的取值,一方面 $x_k$ 取值越大函数值下降越多,另一方面, $x_k$ 的取值受到可行性的限制
	 + 它不能无限增大:当 $y_k\le{0}$ 时,即 $y_k$ 的每个分量均为非正数,则问题不存在有限最优解.

	 + 对某个 $i$ , 当 $y_{ik}\le{0}$ 时, $x_k$ 取任何正值时,总成立 $x_{B_i}\ge0$ ;

	 + 而当 $y_{ik}>0$ 时,为保证 $$x_{B_i}=\stackrel{-}{b}_i-y_{ik}x_k\ge0$$
	   
	   就必须取值 $$x_k\le{\frac{\stackrel{-}{b}_i}{y_{ik}}}$$
	   
	   因此,为使 $x_B\ge{0}$ , 应令
	   
	   $$x_k=\min\{\frac{\stackrel{-}{b}_i}{y_{ik}}|y_{ik}>0\}=\frac{\stackrel{-}{b}_r}{y_{rk}}$$

       - $x_k$ 取值 $\frac{\stackrel{-}{b}_r}{y_{rk}}$ 后,原来的基变量 $x_{B_r}=0$ ,得到新的可行解
	 
	 $$x=(x_{B_1},\ldots,x_{B_{r-1}},0,x_{B_{r+1}},0,\ldots,x_k,0,\ldots,0)^T$$
	 
	 这个解一定是基本可行解,这是因为原来的基 $B=(p_{B_1},\ldots,p_{B_r},\ldots,p_{B_m})$ 中的 $m$ 个列
	 是线性无关的,其中不包括 $p_k$ . 由于 $y_k=B^{-1}p_k$ , 故
	 
	 $$p_k=By_k=\sum_{i=1}^{m}y_{ik}p_{B_i}$$
	 即 $p_k$ 是向量组 $p_{B_1},\ldots,p_{B_r},\ldots,p_{B_m}$ 的线性组合,且系数 $y_{rk}\ne0$ ,因此用 $p_k$ 取代 $p_{B_r}$
	 后,得到的向量组 $p_{B_1},\ldots,p_{k},\ldots,p_{B_m}$ 也是线性无关的.
	 因此新的可行解 $x$ 的正分量对应的列线性无关,故 $x$ 为基本可行解.

    4. 经上述变换, $x_k$ 由原来的非基变量变成基变量,而原来的基变量 $x_{B_r}$ 变成非基变量.在新的基本可行解处,目标函数值比原来减少了
       $(z_k-c_k)x_k$ , 重复以上过程,可以进一步改进基本可行解,直到所有 $z_j-c_j\le0$ ,以致任何一个非基变量取正值都不能使目标函数
       值减少时为止.

    5. 通常称 $z_j-c_j$ 为判别数或检验数.

*** 收敛性							    :Theorem:

    - 定理
      对于非退化问题,单纯形方法经有限次迭代或达到最优基本可行解,或得出无界的结论.

* Chapter 4 对偶原理

** 线性规划中的对偶理论

   线性规划中的对偶可以概括为三种形式:

*** 对称对偶

    - 原问题
      
      \begin{eqnarray}
      min& \ cx\\
      s.t.\ Ax&\ge{}&b\nonumber\\
      x&\ge{}&0\nonumber
      \end{eqnarray}

    - 对偶问题
      
      \begin{eqnarray}
      max&\ wb\\
      s.t.\ wA&\le{}&c\nonumber\\
      w&\ge{}&0\nonumber
      \end{eqnarray}

*** 非对称形式的对偶

    - 具有等式约束的线性规划问题
      
      \begin{eqnarray}
      min\ &cx\nonumber\\
      s.t.\ Ax&=&b\nonumber\\
      x&\ge{}&0\nonumber
      \end{eqnarray}

    - 对偶问题(非对称对偶)
      
      \begin{eqnarray}
      max\ &wb\\
      s.t.\ wA&\le{}&c\nonumber
      \end{eqnarray}

*** 一般情形

    - 原问题
      
      \begin{eqnarray}
      min\ &cx\\
      s.t.\ A_1x&\ge{}&b_1\nonumber\\
      A_2x&=&b_2\nonumber\\
      A_3x&\le{}&b_3\nonumber\\
      x&\ge{}&0\nonumber
      \end{eqnarray}

    - 对偶问题
      
      \begin{eqnarray}
      max\ \ w_1b_1\ +\ w_2b_2&+&w_3b_3\\
      s.t.\ w_1A_1+w_2A_2+w_3A_3&\le{}&c\nonumber\\
      w_1&\ge{}&0\nonumber\\
      w_3&\le{}&0\nonumber
      \end{eqnarray}

*** 对偶定理
    
定理[p127]:设 $x^{(0)},w^{(0)}$ 分别是对称对偶形式的可行解,则 $cx^{(0)}\ge{w^{(0)}b}$ .

   - 推论1:
     若 $x^{(0)}$ 和 $w^{(0)}$ 分别是原问题和对偶问题的可行解,且 $cx^{(0)}=w^{(0)}b$ ,
     则 $x^{(0)}$ 和 $w^{(0)}$ 分别是原问题和对偶问题的最优解.

   - 推论2:
     对偶规划有最优解的充要条件是它们同时有可行解.

   - 推论3:
     若原问题的目标函数值在可行域上无下界,则对偶问题无可行解;反之,若对偶问题的目标函数值在可行域上
     无上界,则原问题无可行解.

定理[p127]:设原问题和对偶问题中有一个问题存在最优解,则另一个问题也存在最优解,且两个问题的目标函数的最优值相等.

   - 推论:
     若线性规划存在一个对应基 $B$ 的最优基本可行解,则单纯形乘子 $w=c_BB^{-1}$ 是对偶问题的一个最优解.

*** 互补松弛定理

定理[p129]:设 $x^{(0)},w^{(0)}$ 分别是原问题和对偶问题的可行解,那么 $x^{(0)}$ 和 $w^{(0)}$ 都是最优解的充要条件
           是,对所有 $i$ 和 $j$ ,下列关系成立:

	   1) 如果 $x_j^{(0)}>0$ ,就有 $w^{(0)}p_j=c_j$

	   2) 如果 $w^{(0)}p_j<c_j$ ,就有 $x_j^{(0)}=0$

	   3) 如果 $w_i^{(0)}>0$ ,就有 $A_ix^{(0)}=b_i$

	   4) 如果 $A_ix^{(0)}>b_i$ ,就有 $w_i^{(0)}=0$

* Chapter 7 最优性条件

** 无约束问题的极值条件

*** 必要条件

    1. 定理[p203]:
       设函数 $f(x)$ 在点 $\overline{x}$ 可微,如果存在方向 $d$ ,使 $\nabla{}f(\overline{x})^Td<0$ ,则存在数 $\delta>0$ ,
       使得对每个 $\lambda\in{(0,\delta)}$ ,有 $f(\overline{x}+\lambda{d})<f(\overline{x})$ .

    2. 定理[p204]:一阶必要条件

       设函数 $f(x)$ 在点 $\overline{x}$ 可微,若 $\overline{x}$ 是局部极小点,则梯度 $\nabla{}f(\overline{x})=0$ .

    3. 定理[p204]:二阶必要条件

       设函数 $f(x)$ 在点 $\overline{x}$ 处二次可微,若 $\overline{x}$ 是局部极小点,则梯度 $\nabla{f(\overline{x})}=0$ ,并且
       Hesse 矩阵 $\nabla^2{}f(\overline{x})$ 半正定.

*** 驻点与鞍点

    1. 满足 $\nabla{}f(x^*)=0$ 的点 $x^*$ 称为函数 $f$ 的稳定点或驻点
    2. 如果 $\nabla{}f(x^*)=0$ ,则 $x^*$ 可能是极小点,也可能是极大点,也可能不是极值点.既不是极小点也不是极大点的稳定点叫做函数的鞍点.

*** 二阶充分条件

    1. 定理[p204]:
       设函数 $f(x)$ 在点 $\overline{x}$ 处二次可微,若梯度 $\nabla{}f(\overline{x})=0$ ,且 Hesse 矩阵
       $\nabla^2{}f(\overline{x})$ 正定,则 $\overline{x}$ 是局部极小点.

*** 凸充要条件

    1. 定理[p205]:
       (假设函数是凸函数,给出全局极小点的充分必要条件)
       设 $f(x)$ 是定义在 $R^n$ 上的可微凸函数, $\overline{x}\in{R^n}$ ,则 $\overline{x}$ 为全局极小点的充要条件是
       $\nabla{}f(\overline{x})=0$ .

*** 下降方向

    1. 定义
       设 $x,d\in{R^n}$ ,若存在常数 $\overline{\alpha}>0$ 使得
       
       $f(x+\alpha{d})<f(x),\ \forall{\alpha}\in{(0,\overline{\alpha})}$
       
       则称 $d$ 是 $f$ 在 $x$ 点处的一个下降方向.

*** 下降算法

    1. 无约束优化的下降算法的基本思想
       从某个初始点 $x^{(0)}$ 出发,构造点列 $\{x^{(k)}\}$ 使得 $f(x^{(k+1)})<f(x^{(k)}),k=0,1,\cdots$ .
       算法的目标是点列 $\{x^{(k)}\}$ 中的某个点或某个极限点是目标函数的解或稳定点.

    2. 算法
       
       1) 给定初始点 $x^{(0)}\in{R^n}$ ,精度 $\varepsilon\ge{0}$ .令 $k=0$

       2) 若 $\|\nabla{}f(x^{(k)})\|\le{\varepsilon}$ ,停止,得解 $x^{(k)}$ ,否则转步3

       3) 确定下降方向 $d^{(k)}$ ,使得 $\nabla{}f(x^{(k)})^Td^{(k)}<0$

       4) 确定步长 $\alpha_k>0$ ,使得 $f(x^{(k)}+\alpha_kd^{(k)})<f(x^{(k)})$

       5) 令 $x^{(k+1)}=x^{(k)}+\alpha_kd^{(k)},k:=k+1$ ,转步2
	
*** 一维搜索

**** 精确线搜索
     精确线搜索通过求解一维最优化问题

     $\min_{\alpha>0}f(x^{(k)}+\alpha{}d^{(k)})\stackrel{\triangle}{=}\phi(\alpha)$

     得步长 $\alpha_k$ ,则有

     $\nabla{}f(x^{(k)}+\alpha_kd^{(k)})^Td^{(k)}=0$

     即取 $\alpha_k=\arg{}\min_{\alpha>0}\phi(\alpha)=f(x^{(k)}+\alpha{}d^{(k)})$ ,

     这时 $\alpha_k$ 称为最优步长.这种方法不仅能保证满足下降条件,而且在 $d^{(k)}$ 方向上使下降量
     $D=f(x^{(k)})-f(x^{(k)}+\alpha_kd^{(k)})$ 达到最大,但一般需要较大的
     计算量.

**** 非精确线搜索

     精确线搜索的目的是为了获得最优步长,一般需要较大的计算量.非精确线搜索的目的则是求得使目标函数值
     达到一定下降量的解,即可接受步长,一般只需要较小的计算量.

*** Armijo 型线搜索

    设 $d^{(k)}$ 是 $f$ 在 $x^{(k)}$ 处的一个下降方向,满足 $\nabla{}f(x^{(k)})^Td^{(k)}<0$

    给定 $\sigma_1\in{(0,1)}$ ,取 $\alpha_k>0$ ,使得

    $f(x^{(k)}+\alpha_kd^{(k)})\le{}f(x^{(k)})+\sigma_1\alpha_k\nabla{}f(x^{(k)})^Td^{(k)}$

    即

    $\phi{}(\alpha_k)\le{}\phi{}(0)+\sigma_1\alpha_k\phi{}^{'}(0)$

     易知,上式对充分小的 $\alpha_k$ 均成立,通常希望 $\alpha_k$ 尽可能的大.设 $\beta>0,\rho\in{(0,1)}$ ,一般
     取 $\alpha_k$ 为集合 $\{\beta{}\rho{}^i,i=0,1,\cdots\}$ 中使得上式成立的最大值.

     - 算法
       1) 若 $\alpha_k=1$ 满足上式,则取 $\alpha_k=1$ ,否则转2

       2) 给定常数 $\beta>0,\rho\in{(0,1)}$ ,令 $\alpha_k=\beta$

       3) 若 $\alpha_k$ 满足上式,则终止计算,并得步长 $\alpha_k$ ,否则转4

       4) 令 $\alpha_k:=\rho\alpha_k$ ,转3

** 约束极值问题
       
