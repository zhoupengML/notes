#+OPTIONS: tex:t
#+TITLE: 最优化
#+AUTHOR: Peng Zhou


* Chapter 1 凸集与凸函数
** 凸函数的判别

   1. 设$f:R^n\to{R}$ , 且二阶连续可微， 则下列命题等价

      1) $f$ 是凸函数

      2) 对 $\forall{x, y} \in{R^n}$ , 有 $f(y)\ge{f(x)+\nabla{f(x)^T}(y-x)}$

      3) 梯度函数 $\nabla{f(x)}$ 单调

	 $$[\nabla{f(y)}-\nabla{f(x)}]^T(y-x)\ge{0}$$

      4) $\forall{x}\in{R^n} , Hesse$ 矩阵 $\nabla^2{f(x)}$ 半正定 (正定矩阵: positive definite matrix)

   2. 定理[p20]:
      设 $S$ 是 $R^n$ 中非空开凸集, $f(x)$ 是定义在 $S$ 上的可微函数,则 $f(x)$ 为凸函数的充要条件是
      对任意两点 $x^{(1)},x^{(2)}\in{S}$ ,都有

      $f(x^{(2)})\ge{}f(x^{(1)})+\nabla{}f(x^{(1)})^T(x^{(2)}-x^{(1)})$

      而 $f(x)$ 为严格凸函数的充要条件是对任意的互不相同的 $x^{(1)},x^{(2)}\in{S}$ ,成立
      
      $f(x^{(2)})>f(x^{(1)})+\nabla{}f(x^{(1)})^T(x^{(2)}-x^{(1)})$

*** 正定二次型的定义 [[http://wenku.baidu.com/link?url=J912nnUKjFJYkRt-w89TPkotscm0SnFl4XwYXHSrxOEDau0TLibvB9J3K81hKOyH-B3K3JWS2_hE9lW6eFj7S1GhD8wDhOg7nqpU2QQ7oLO][ref]]

    * 定义
      在实二次型 $f(x_1,x_2,...,x_n)$ 中, 若对于任意一组不全为 $0$ 的实数 $c_1,c_2,...,c_n$ ,
      都有 $f(x_1,x_2,...,x_n)>0$ , 则称该二次型为正定的; 
      若 $f(x_1,x_2,...,x_n)\ge{0}$ , 则称 $f$ 为半正定二次型; 
      若 $f(x_1,x_2,...,x_n)<0$ , 则称 $f$ 为负定二次型; 
      若 $f(x_1,x_2,...,x_n)\le{0}$ , 则称 $f$ 为半负定二次型;
      若实二次型既不是半正定又不是半负定的则称为不定二次型.
      
*** 正定矩阵的定义 [[http://wenku.baidu.com/link?url=J912nnUKjFJYkRt-w89TPkotscm0SnFl4XwYXHSrxOEDau0TLibvB9J3K81hKOyH-B3K3JWS2_hE9lW6eFj7S1GhD8wDhOg7nqpU2QQ7oLO][ref]]

    * 定义
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 正定, 则称实对称矩阵 $A$ 正定;
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 半正定, 则称实对称矩阵 $A$ 半正定;
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 负定, 则称实对称矩阵 $A$ 负定;
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 半负定, 则称实对称矩阵 $A$ 半负定;
      若实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 不定, 则称实对称矩阵 $A$ 不定.

*** 正定矩阵的判定

**** 正定矩阵判定定理

     1. $n$ 元实二次型 $f(x_1,x_2,...,x_n)=X^TAX$ 是正定的充要条件是:
	它的标准型的系数全为正.
	
	+ 用合同变换法化二次型为标准型 [[http://wenku.baidu.com/link?url=1M3RiheBvR4d7sHe1S4htMZzH902EgWo0APzOax7F5oREnwilnTwWQI-F0Els_uinKhevcOL9lPRQnM6-PFL34kUTC96jdC4bwwQRsMDsNS][ref]]

	  1) 写出二次型的矩阵 $A$

	  2) 作 $(A\ E)\xrightarrow[elementary\ row\ operation\ of\ E]{congruent\ transformation\ of\ A}(\land{\ P^T})$ , 求出 $P^T$

	  3) 作非退化的线性变换 $X=PY$ , 将二次型化为标准型
      
*** 矩阵的等价, 相似, 合同 [[http://wenku.baidu.com/link?url=QRehRaAsSmbyVxbYFkyJQRkXw5y-KmKN0eSoFwW7sU--566tbOd3m5NEtCHw8s6LEN4Y_RGH3nMugFTvABikDMFrcjf3ZbOQMVBNR9ZrFI_][ref]]

**** 矩阵等价的定义

     如果矩阵 $A$ 可以经过一系列初等变换变成 $B$ , 则 $A$ 与 $B$ 等价,
     记为 $A\cong{B}$ .

**** 矩阵相似的定义
     
     设 $A,B$ 是数域 $F$ 上的 $n$ 阶方阵, 如果存在数域 $F$ 上的 $n$ 阶
     可逆矩阵 $P$ , 使得 $B=P^{-1}AP$ , 则称 $A$ 与 $B$ 相似,
     记为 $A\sim{B}$ .

**** 矩阵合同的定义
     
     设 $A,B$ 是数域 $F$ 上的 $n$ 阶方阵, 如果存在数域 $F$ 上的 $n$ 阶
     可逆矩阵 $P$ , 使得 $P^{T}AP=B$ , 则称在数域 $F$ 上 $A$ 与 $B$ 合同.


*  Chapter 2 线性规划的基本性质

** 线性规划标准形式
   \begin{eqnarray}
    \min{}&\ &\sum_{j=1}^{n}{c_jx_j}\\
    s.t.\ \ \sum_{j=1}^{n}\alpha_{ij}x_j&=&b_i, i=1,...,m\nonumber\\
    x_j&\ge&{0}, j=1,...,n\nonumber
   \end{eqnarray}

矩阵形式:

   \begin{eqnarray}
    \label{eq:2}
    \min&{c^Tx}&\\
    s.t.\ \ Ax&=&b\nonumber\\
    x&\ge&{0}\nonumber
   \end{eqnarray}

**  可行域
    1. 在线性规划中,约束条件均为线性等式及不等式,满足这些条件的点的集合是凸集
    2. 线性规划的可行域是凸集

** 最优极点							    :Theorem:
   1.线性规划如果存在最优解,那么最优值一定能在某极点上达到

   2.设可行域的极点为 $x^{(1)},x^{(2)},...,x^{(k)}$, 极方向为 $d^{(1)},d^{(2)},...,d^{(l)}$, 根据定理[p12],
      任何可行点 $x$ 可以表示为

      \begin{eqnarray}
      x=\sum_{j=1}^k\lambda_jx^{(j)}&+&\sum_{j=1}^l\mu_jd^{(j)}\\
      \sum_{j=1}^k\lambda_j&=&1\nonumber\\
      \lambda_j&\ge&{0},\ j=1,...,k\nonumber\\
      \mu_j&\ge&0,\ j=1,...,l
      \end{eqnarray}

   - 定理2.2.2 设线性规划的可行域非空,则
     1) 线性规划存在有限最优解的充要条件是所有 $c^Td^{(j)}$  为非负数.
     2) 若线性规划存在有限最优解,则目标函数的最优值可在某个极点上达到.

**  最优基本可行解						    :Theorem:
    1. 对于线性规划,基本可行解与可行域的极点之间总存在着对应关系.
       
    2. 定理2.2.3 
       令 $K=\{x|Ax=b,x\ge{0}\},A$ 是 $m\times{n}$ 矩阵, $A$  的秩为 $m$, 则 $K$
        的极点集与 $Ax=b,x\ge{0}$ 的基本可行解集等价.

    3.  线性规划问题的求解,可归结为求最优基本可行解.

** 基本可行解的存在问题						    :Theorem:
   1. 定理1.4.1 [p12]
       若多面集 $S=\{x|Ax=b,x\ge{0}\}$ 非空,则存在有限个极点(有限个基本可行解).
   2. 定理2.2.4 [p34]
      如果 $Ax=b,x\ge{0}$  有可行解,则一定存在基本可行解.其中 $A$ 是 $m\times{n}$ 矩阵,
      $A$ 的秩为 $m$.

** Practice								:Def:
   1. 定义2.2.1 基本解 [p30]
      
      \begin{equation}
      x=\begin{bmatrix}x_B\\x_N\end{bmatrix}
      =\begin{bmatrix}B^{-1}b\\0\end{bmatrix}
      \end{equation}
      
       称为方程组 $Ax=b$  的一个基本解. 矩阵 $A$ 的秩为 $m$, $A=[B,N]$, $B$  是 $m$ 阶
       可逆矩阵.

* Chapter 3 单纯形方法

** 单纯形方法原理

*** 基本可行解的转换
    
    1. 若线性规划有最优解,则必存在最优基本可行解.
    2. 单纯形方法的基本思想,就是从一个基本可行解出发,求一个使目标函数值有所改善的基本可行解,通过
       不断改进基本可行解,力图达到最优基本可行解.
    3. 
        \begin{eqnarray}
	    \min\ f& \stackrel{def}{=}&cx\\
	    s.t.\ Ax&=&b\nonumber\\
	    x&\ge&0\nonumber
	\end{eqnarray}

       - $A_{m\times{n}}$ , $rank(A)=m$ ,$c$ : $n$ 维行向量, $x$ : $n$ 维列向量, $b\ge0$ 是 $m$ 维列向量.

       - 记 $$A=(p_1,p_2,...,p_n)$$

       - 将 $A$ 分解成 $(B,N)$ ,使得其中 $B$ 是基矩阵, $N$ 是非基矩阵,设 

	 \begin{eqnarray}
	 x^{(0)}=
         \begin{bmatrix}
	 B^{-1}b\\0
         \end{bmatrix}
         \end{eqnarray}

	 是基本可行解,在 $x^{(0)}$ 处的目标函数值
	 
	 \begin{eqnarray}
	 f_{0}=cx^{(0)}=(c_{B},c_{N})
	 \begin{bmatrix}B^{-1}b\\0 \end{bmatrix}
	 =c_BB^{-1}b
         \end{eqnarray}
	 
	 $c_B$ 是 $c$ 中与基变量对应的分量组成的 $m$ 维行向量. $c_N$ 是 $c$ 中与非基变量对应的分量组成的 $n-m$ 维行向量.

       - 现在分析怎么从基本可行解 $x^{(0)}$ 出发,求一个改进的基本可行解. 设 
	 
	 \begin{eqnarray}
	 x=
	 \begin{bmatrix}x_B\\x_N  \end{bmatrix}
	 \end{eqnarray}
	 
	 是任一个可行解,则由 $Ax=b$ 得到 $$x_{B}=B^{-1}b-B^{-1}Nx_N$$ ,在点 $x$ 处的目标函数值
	 
	 \begin{eqnarray}
	 \label{eq:1}
	 f&=&cx=(c_B,c_N)
	 \begin{bmatrix}x_B\\x_N    \end{bmatrix}\\
	 &=&c_Bx_B+c_Nx_N\nonumber\\
	 &=&c_B(B^{-1}b-B^{-1}Nx_N)+c_Nx_N\nonumber\\
	 &=&c_BB^{-1}b-(c_BB^{-1}N-c_N)x_N\nonumber\\
	 &=&f_0-\sum_{j\in{R}}(c_BB^{-1}p_j-c_j)x_j\nonumber\\
	 &=&f_0-\sum_{j\in{R}}(z_j-c_j)x_j\nonumber
         \end{eqnarray}
	 
	 其中 $R$ 是非基变量下标集
	 
	 $$z_j=c_BB^{-1}p_j$$
	 
	 由上式可知,适当选取自由未知量 $x_j(j\in{R})$ 的数值就有可能使得 
	 
	 \begin{equation} \sum_{j\in{R}}(z_j-c_j)x_j>0	 \end{equation}
	 
	 从而得到使目标函数值减少的新的基本可行解.为此,在原来的 $n-m$ 个非基变量中,使得 $n-m-1$ 个变量仍然取零值,
	 而另一个非基变量,比如 $x_k$ 增大,即取正值.怎样确定下标 $k$ 呢?当 $x_j(j\in{R})$ 取值相同时, $z_j-c_j$ (正数)越大,目标函数值
	 下降越多,因此选择 $x_k$, 使
	 
	 \begin{equation}z_k-c_k=\max_{j\in{R}}\{z_j-c_j\}    \end{equation}
	 
	 这里假设 $z_k-c_k>0$

       - $x_k$ 由零变为正数后,得到方程组 $Ax=b$ 的解
	 
	 \begin{eqnarray}x_B=B^{-1}b-B^{-1}p_kx_k=\stackrel{-}{b}-y_kx_k    \end{eqnarray}
    	 
	 其中 $\stackrel{-}{b}$ 和 $y_k$ 是 $m$ 维列向量, $\stackrel{-}{b}=B^{-1}b , y_k=B^{-1}p_k$ , 把 $x_B$ 按分量写出,即
	 
	 \begin{eqnarray}
	 x_B=
	 \begin{bmatrix}
	 x_{B_1}\\x_{B_2}\\\vdots\\x_{B_m}    \end{bmatrix}
	 = \begin{bmatrix}\stackrel{-}{b}_1\\\stackrel{-}{b}_2\\\vdots\\\stackrel{-}{b}_m    \end{bmatrix}
	 - \begin{bmatrix}y_{1k}\\y_{2k}\\\vdots\\y_{mk}    \end{bmatrix}
	 x_k
	 \end{eqnarray}
	 
	 $$x_N=(0,\ldots,0,x_k,0,\ldots,0)^T$$

       - 在新得到的点,目标函数值是
	 
	 $$f=f_0-(z_k-c_k)x_k$$

       - 再来分析 $x_k$ 的取值,一方面 $x_k$ 取值越大函数值下降越多,另一方面, $x_k$ 的取值受到可行性的限制
	 + 它不能无限增大:当 $y_k\le{0}$ 时,即 $y_k$ 的每个分量均为非正数,则问题不存在有限最优解.

	 + 对某个 $i$ , 当 $y_{ik}\le{0}$ 时, $x_k$ 取任何正值时,总成立 $x_{B_i}\ge0$ ;

	 + 而当 $y_{ik}>0$ 时,为保证 $$x_{B_i}=\stackrel{-}{b}_i-y_{ik}x_k\ge0$$
	   
	   就必须取值 $$x_k\le{\frac{\stackrel{-}{b}_i}{y_{ik}}}$$
	   
	   因此,为使 $x_B\ge{0}$ , 应令
	   
	   $$x_k=\min\{\frac{\stackrel{-}{b}_i}{y_{ik}}|y_{ik}>0\}=\frac{\stackrel{-}{b}_r}{y_{rk}}$$

       - $x_k$ 取值 $\frac{\stackrel{-}{b}_r}{y_{rk}}$ 后,原来的基变量 $x_{B_r}=0$ ,得到新的可行解
	 
	 $$x=(x_{B_1},\ldots,x_{B_{r-1}},0,x_{B_{r+1}},0,\ldots,x_k,0,\ldots,0)^T$$
	 
	 这个解一定是基本可行解,这是因为原来的基 $B=(p_{B_1},\ldots,p_{B_r},\ldots,p_{B_m})$ 中的 $m$ 个列
	 是线性无关的,其中不包括 $p_k$ . 由于 $y_k=B^{-1}p_k$ , 故
	 
	 $$p_k=By_k=\sum_{i=1}^{m}y_{ik}p_{B_i}$$
	 即 $p_k$ 是向量组 $p_{B_1},\ldots,p_{B_r},\ldots,p_{B_m}$ 的线性组合,且系数 $y_{rk}\ne0$ ,因此用 $p_k$ 取代 $p_{B_r}$
	 后,得到的向量组 $p_{B_1},\ldots,p_{k},\ldots,p_{B_m}$ 也是线性无关的.
	 因此新的可行解 $x$ 的正分量对应的列线性无关,故 $x$ 为基本可行解.

    4. 经上述变换, $x_k$ 由原来的非基变量变成基变量,而原来的基变量 $x_{B_r}$ 变成非基变量.在新的基本可行解处,目标函数值比原来减少了
       $(z_k-c_k)x_k$ , 重复以上过程,可以进一步改进基本可行解,直到所有 $z_j-c_j\le0$ ,以致任何一个非基变量取正值都不能使目标函数
       值减少时为止.

    5. 通常称 $z_j-c_j$ 为判别数或检验数.

*** 收敛性							    :Theorem:

    - 定理
      对于非退化问题,单纯形方法经有限次迭代或达到最优基本可行解,或得出无界的结论.

* Chapter 4 对偶原理

** 线性规划中的对偶理论

   线性规划中的对偶可以概括为三种形式:

*** 对称对偶

    - 原问题
      
      \begin{eqnarray}
      min& \ cx\\
      s.t.\ Ax&\ge{}&b\nonumber\\
      x&\ge{}&0\nonumber
      \end{eqnarray}

    - 对偶问题
      
      \begin{eqnarray}
      max&\ wb\\
      s.t.\ wA&\le{}&c\nonumber\\
      w&\ge{}&0\nonumber
      \end{eqnarray}

*** 非对称形式的对偶

    - 具有等式约束的线性规划问题
      
      \begin{eqnarray}
      min\ &cx\nonumber\\
      s.t.\ Ax&=&b\nonumber\\
      x&\ge{}&0\nonumber
      \end{eqnarray}

    - 对偶问题(非对称对偶)
      
      \begin{eqnarray}
      max\ &wb\\
      s.t.\ wA&\le{}&c\nonumber
      \end{eqnarray}

*** 一般情形

    - 原问题
      
      \begin{eqnarray}
      min\ &cx\\
      s.t.\ A_1x&\ge{}&b_1\nonumber\\
      A_2x&=&b_2\nonumber\\
      A_3x&\le{}&b_3\nonumber\\
      x&\ge{}&0\nonumber
      \end{eqnarray}

    - 对偶问题
      
      \begin{eqnarray}
      max\ \ w_1b_1\ +\ w_2b_2&+&w_3b_3\\
      s.t.\ w_1A_1+w_2A_2+w_3A_3&\le{}&c\nonumber\\
      w_1&\ge{}&0\nonumber\\
      w_3&\le{}&0\nonumber
      \end{eqnarray}

*** 对偶定理
    
定理[p127]:设 $x^{(0)},w^{(0)}$ 分别是对称对偶形式的可行解,则 $cx^{(0)}\ge{w^{(0)}b}$ .

   - 推论1:
     若 $x^{(0)}$ 和 $w^{(0)}$ 分别是原问题和对偶问题的可行解,且 $cx^{(0)}=w^{(0)}b$ ,
     则 $x^{(0)}$ 和 $w^{(0)}$ 分别是原问题和对偶问题的最优解.

   - 推论2:
     对偶规划有最优解的充要条件是它们同时有可行解.

   - 推论3:
     若原问题的目标函数值在可行域上无下界,则对偶问题无可行解;反之,若对偶问题的目标函数值在可行域上
     无上界,则原问题无可行解.

定理[p127]:设原问题和对偶问题中有一个问题存在最优解,则另一个问题也存在最优解,且两个问题的目标函数的最优值相等.

   - 推论:
     若线性规划存在一个对应基 $B$ 的最优基本可行解,则单纯形乘子 $w=c_BB^{-1}$ 是对偶问题的一个最优解.

*** 互补松弛定理

定理[p129]:设 $x^{(0)},w^{(0)}$ 分别是原问题和对偶问题的可行解,那么 $x^{(0)}$ 和 $w^{(0)}$ 都是最优解的充要条件
           是,对所有 $i$ 和 $j$ ,下列关系成立:

	   1) 如果 $x_j^{(0)}>0$ ,就有 $w^{(0)}p_j=c_j$

	   2) 如果 $w^{(0)}p_j<c_j$ ,就有 $x_j^{(0)}=0$

	   3) 如果 $w_i^{(0)}>0$ ,就有 $A_ix^{(0)}=b_i$

	   4) 如果 $A_ix^{(0)}>b_i$ ,就有 $w_i^{(0)}=0$

* Chapter 7 最优性条件

** 无约束问题的极值条件

*** 必要条件

    1. 定理[p203]:
       设函数 $f(x)$ 在点 $\overline{x}$ 可微,如果存在方向 $d$ ,使 $\nabla{}f(\overline{x})^Td<0$ ,则存在数 $\delta>0$ ,
       使得对每个 $\lambda\in{(0,\delta)}$ ,有 $f(\overline{x}+\lambda{d})<f(\overline{x})$ .

    2. 定理[p204]:一阶必要条件

       设函数 $f(x)$ 在点 $\overline{x}$ 可微,若 $\overline{x}$ 是局部极小点,则梯度 $\nabla{}f(\overline{x})=0$ .

    3. 定理[p204]:二阶必要条件

       设函数 $f(x)$ 在点 $\overline{x}$ 处二次可微,若 $\overline{x}$ 是局部极小点,则梯度 $\nabla{f(\overline{x})}=0$ ,并且
       Hesse 矩阵 $\nabla^2{}f(\overline{x})$ 半正定.

*** 驻点与鞍点

    1. 满足 $\nabla{}f(x^*)=0$ 的点 $x^*$ 称为函数 $f$ 的稳定点或驻点
    2. 如果 $\nabla{}f(x^*)=0$ ,则 $x^*$ 可能是极小点,也可能是极大点,也可能不是极值点.既不是极小点也不是极大点的稳定点叫做函数的鞍点.

*** 二阶充分条件

    1. 定理[p204]:
       设函数 $f(x)$ 在点 $\overline{x}$ 处二次可微,若梯度 $\nabla{}f(\overline{x})=0$ ,且 Hesse 矩阵
       $\nabla^2{}f(\overline{x})$ 正定,则 $\overline{x}$ 是局部极小点.

*** 凸充要条件

    1. 定理[p205]:
       (假设函数是凸函数,给出全局极小点的充分必要条件)
       设 $f(x)$ 是定义在 $R^n$ 上的可微凸函数, $\overline{x}\in{R^n}$ ,则 $\overline{x}$ 为全局极小点的充要条件是
       $\nabla{}f(\overline{x})=0$ .

*** 下降方向

    1. 定义
       设 $x,d\in{R^n}$ ,若存在常数 $\overline{\alpha}>0$ 使得
       
       $f(x+\alpha{d})<f(x),\ \forall{\alpha}\in{(0,\overline{\alpha})}$
       
       则称 $d$ 是 $f$ 在 $x$ 点处的一个下降方向.

*** 下降算法

    1. 无约束优化的下降算法的基本思想
       从某个初始点 $x^{(0)}$ 出发,构造点列 $\{x^{(k)}\}$ 使得 $f(x^{(k+1)})<f(x^{(k)}),k=0,1,\cdots$ .
       算法的目标是点列 $\{x^{(k)}\}$ 中的某个点或某个极限点是目标函数的解或稳定点.

    2. 算法
       
       1) 给定初始点 $x^{(0)}\in{R^n}$ ,精度 $\varepsilon\ge{0}$ .令 $k=0$

       2) 若 $\|\nabla{}f(x^{(k)})\|\le{\varepsilon}$ ,停止,得解 $x^{(k)}$ ,否则转步3

       3) 确定下降方向 $d^{(k)}$ ,使得 $\nabla{}f(x^{(k)})^Td^{(k)}<0$

       4) 确定步长 $\alpha_k>0$ ,使得 $f(x^{(k)}+\alpha_kd^{(k)})<f(x^{(k)})$

       5) 令 $x^{(k+1)}=x^{(k)}+\alpha_kd^{(k)},k:=k+1$ ,转步2
	
*** 一维搜索

**** 精确线搜索
     精确线搜索通过求解一维最优化问题

     $\min_{\alpha>0}f(x^{(k)}+\alpha{}d^{(k)})\stackrel{\triangle}{=}\phi(\alpha)$

     得步长 $\alpha_k$ ,则有

     $\nabla{}f(x^{(k)}+\alpha_kd^{(k)})^Td^{(k)}=0$

     即取 $\alpha_k=\arg{}\min_{\alpha>0}\phi(\alpha)=f(x^{(k)}+\alpha{}d^{(k)})$ ,

     这时 $\alpha_k$ 称为最优步长.这种方法不仅能保证满足下降条件,而且在 $d^{(k)}$ 方向上使下降量
     $D=f(x^{(k)})-f(x^{(k)}+\alpha_kd^{(k)})$ 达到最大,但一般需要较大的
     计算量.

**** 非精确线搜索

     精确线搜索的目的是为了获得最优步长,一般需要较大的计算量.非精确线搜索的目的则是求得使目标函数值
     达到一定下降量的解,即可接受步长,一般只需要较小的计算量.

***** Armijo 型线搜索

    设 $d^{(k)}$ 是 $f$ 在 $x^{(k)}$ 处的一个下降方向,满足 $\nabla{}f(x^{(k)})^Td^{(k)}<0$

    给定 $\sigma_1\in{(0,1)}$ ,取 $\alpha_k>0$ ,使得

    $f(x^{(k)}+\alpha_kd^{(k)})\le{}f(x^{(k)})+\sigma_1\alpha_k\nabla{}f(x^{(k)})^Td^{(k)}$

    即

    $\phi{}(\alpha_k)\le{}\phi{}(0)+\sigma_1\alpha_k\phi{}^{'}(0)$

     易知,上式对充分小的 $\alpha_k$ 均成立,通常希望 $\alpha_k$ 尽可能的大.设 $\beta>0,\rho\in{(0,1)}$ ,一般
     取 $\alpha_k$ 为集合 $\{\beta{}\rho{}^i,i=0,1,\cdots\}$ 中使得上式成立的最大值.

     - 算法
       1) 若 $\alpha_k=1$ 满足上式,则取 $\alpha_k=1$ ,否则转2

       2) 给定常数 $\beta>0,\rho\in{(0,1)}$ ,令 $\alpha_k=\beta$

       3) 若 $\alpha_k$ 满足上式,则终止计算,并得步长 $\alpha_k$ ,否则转4

       4) 令 $\alpha_k:=\rho\alpha_k$ ,转3

*** 牛顿法

**** 无约束非线性规划问题

     $\min_{x\in{R^n}}f(x)$

     其中 $f(x)$ 二次连续可微.
     
    - 设 $x^{(k)}$ 是当前迭代点,则 $f(x)$ 在 $x^{(k)}$ 处的 Taylor 展式为
      \begin{eqnarray}
       f(x)&=&f(x^{(k)})+\nabla{}f(x^{(k)})^T(x-x^{(k)})\\
       &+&\frac{1}{2}(x-x^{(k)})^T\nabla^2f(x^{(k)})(x-x^{(k)})\\
           &+&o(\|(x-x^{(k)})\|^2)
      \end{eqnarray}

    - 故考虑二次规划问题
      \begin{eqnarray}
      \min_{x}f(x)&=&\nabla{}f(x^{(k)})^T(x-x^{(k)})\\
      &+&\frac{1}{2}(x-x^{(k)})^T\nabla^2f(x^{(k)})(x-x^{(k)})\\
      &+&o(\|(x-x^{(k)})\|^2)
      \end{eqnarray}
      
      当 $\nabla^2f(x^{(k)})$ 正定时,上述问题的最优解为

      \begin{eqnarray}
      \tilde{x}=x^{(k)}-[\nabla^2f(x^{(k)})]^{-1}\nabla{}f(x^{(k)})
      \end{eqnarray}

      将 $\tilde{x}$ 作为新的迭代点 $x^{(k+1)}$ ,得到
      
      \begin{eqnarray}
      x^{(k+1)}=x^{(k)}-[\nabla^2f(x^{(k)})]^{-1}\nabla{}f(x^{(k)})
      \end{eqnarray}

    - 若记
      
      \begin{eqnarray}
      d^{(k)}=-[\nabla^2f(x^{(k)})]^{-1}\nabla{}f(x^{(k)})
      \end{eqnarray}
      
      则
      $x^{(k+1)}=x^{(k)}+d^{(k)}$
      
      $d^{(k)}$ 称为 $f(x)$ 在 $x^{(k)}$ 处的 Newton 方向.

    - 因此,牛顿法就是以 Newton 方向为搜索方向,以 $1$ 为步长(即简单一维搜索)进行迭代的方法.

**** 算法(Newton法)

     1) 选定初始数据.给定初始点 $x^{(0)}\in{R^n}$ ,精度参数 $\varepsilon\ge0$ ,令 $k=0$

     2) 终止判别.若 $\|\nabla{}f(x^{(k)})\|\le{\varepsilon}$ ,停止,得 $\tilde{x}=x^{(k)}$,否则转步3

     3) 构造搜索方向.求解线性方程组 $\nabla^2f(x^{(k)})d=-\nabla{}f(x^{(k)})$ 得 $d^{(k)}$

     4) 确定新的迭代点.令 $x^{(k+1)}=x^{(k)}+d^{(k)},k:=k+1$ ,转步2

**** 算法分析

     - 对于一般的无约束凸二次规划问题,Newton 法具有二次终止性(即经过一次迭代就得到精确的最优解).

     - 在一定条件下,若初始点在最优解附件,则 Newton 法具有二阶收敛速度.

     - 对于一般的无约束非线性规划问题,用 Newton 法求解时,既不能保证经过有限次迭代得到精确最优解,
       也不能保证该算法具有收敛性,并且 Newton 方向不一定是下降方向.

*** 拟牛顿法

    - Newton 法虽然具有收敛性的优点,但由于在构造 Newton 方向时需要计算目标函数在迭代点处的 Hesse 阵
    的逆阵,计算量非常大.

    - 拟牛顿法就是为减少 Newton 法的计算量而产生的一种方法,其思想是:用某个正定矩阵代替 Newton 方向中的 Hesse 阵.
    
**** 拟 Newton 方程

     - 考虑无约束非线性规划问题
       
       $\min_{x\in{R^n}}f(x)$
       
       其中 $f(x)$ 二次连续可微.

     - 设 $x^{(k)}$ 是当前迭代点, $H_k\in{}R^{n\times{n}}$ 是对称矩阵, $B_k=H_k^{-1}$ ,令

       $d^{(k)}=-H_k\nabla{}f(x^{(k)})=-B_k^{-1}\nabla{}f(x^{(k)})$
       
       将 $d^{(k)}$ 作为 $f$ 在 $x^{(k)}$ 处的搜索方向.显然,当 $H_k$ 正定时, $d^{(k)}$ 是 $f$ 在 $x^{(k)}$
       处的下降方向.

     - 为了继承 Newton 法的二次收敛速度,我们希望 $H_k$ 是 $[\nabla^2f(x^{(k)})]^{-1}$ 的某种近似.
       为此,先考虑 $[\nabla^2f(x^{(k)})]^{-1}$ 的性质.
       利用梯度函数 $\nabla{}f(x)$ 的 Taylor 展式:
       
       $\nabla{}f(x^{(k)})\approx{}\nabla{}f(x^{(k+1)})+\nabla^2f(x^{(k+1)})(x^{(k)}-x^{(k+1)})$
       
       即
       
       $\nabla{}f(x^{(k)})-\nabla{}f(x^{(k+1)})\approx\nabla^2f(x^{(k+1)})(x^{(k)}-x^{(k+1)})$
       
       
       记 $s^{(k)}=x^{(k+1)}-x^{(k)},y^{(k)}=\nabla{}f(x^{(k+1)})-\nabla{}f(x^{(k)})$ ,则有上式
       
       $y^{(k)}\approx{}\nabla^2f(x^{(k+1)})s^{(k)}$ , $or$ $[\nabla^2{}f(x^{(k+1)})]^{-1}y^{(k)}\approx{}s^{(k)}$
       
       因此,为使 $H_{k+1}$ 是 $[\nabla^2f(x^{(k+1)})]^{-1}$ 的某种近似,要求 $H_{k+1}$ 满足

       $H_{k+1}y^{(k)}=s^{(k)}$

       上式称为关于 $H_{k+1}$ 的拟牛顿方程,它刻画了 $H_{k+1}$ 近似于 $[\nabla^2f(x^{(k+1)})]^{-1}$ 时应具有的
       一个重要特性.

       $B_{k+1}$ 应满足

       $B_{k+1}s^{(k)}=y^{(k)}$

       上式称为关于 $B_{k+1}$ 的拟牛顿方程.这时, $d^{(k)}=-H_k\nabla{}f(x^{(k)})=-B_k^{-1}\nabla{}f(x^{(k)})$
       称为 $f$ 在 $x^{(k)}$ 处的拟牛顿方向.上式表明 $B_{k+1}$ 与 $\nabla^2f(x^{(k+1)})$ 沿方向 $d^{(k)}$ 近似相等.因而,拟牛顿方向
       是牛顿方向在某种意义上的一个近似.

*** 共轭梯度法

**** 共轭方向

     - 定义[p291]
       设 $A$ 是 $n\times{n}$ 对称正定矩阵,若 $R^n$ 中的两个方向 $d^{(1)}$ 和 $d^{(2)}$ 满足
       
       $d^{(1)T}Ad^{(2)}=0$
       
       则称这两个方向关于 $A$ 共轭,或称它们关于 $A$ 正交.

     - 若 $d^{(1)},d^{(2)},\cdots,d^{(k)}$ 是 $R^n$ 中 $k$ 个方向,它们两两关于 $A$ 共轭,即满足
       
       $d^{(i)T}Ad^{(j)}=0,i\ne{j};i,j=1,\cdots,k$
       
       则称这组方向是 $A$ 共轭的,或称它们为 $A$ 的 $k$ 个共轭方向.

     - 若 $A$ 是单位矩阵,则两个方向关于 $A$ 共轭等价于两个方向正交.

***** 共轭方向的性质

      1. 定理[p292]

	 设 $A$ 是 $n$ 阶对称正定矩阵, $d^{(1)},d^{(2)},\cdots,d^{(k)}$ 是 $k$ 个 $A$ 共轭
	 的非零向量,则这个向量组线性无关.

      2. 扩张子空间定理[p293]

	 设有函数
	
	 $f(x)=\frac{1}{2}x^TAx+b^Tx+c$
	
	 其中 $A$ 是 $n$ 阶对称正定矩阵(严格凸函数), $d^{(1)},d^{(2)},\cdots,d^{(k)}$ 是 $A$ 共轭的非零向量.
	 以任意的 $x^{(1)}\in{R^n}$ 为初始点,依次沿 $d^{(1)},d^{(2)},\cdots,d^{(k)}$ 进行一维
	 搜索,得到点 $x^{(2)},x^{(3)},\cdots,x^{(k+1)}$ ,则 $x^{(k+1)}$ 是函数 $f(x)$ 在
	 线性流形

	 $x^{(1)}+\beta_k$

	 上的唯一极小点.特别地,当 $k=n$ 时, $x^{(n+1)}$ 是函数 $f(x)$ 在 $R^n$ 上的唯一极小点.
	 其中
	
	 $\beta_k=\{x\mid{}x=\sum_{i=1}^k\lambda_id^{(i)},\lambda_i\in(-\infty,+\infty)\}$

      3. 推论[p294]
	 
	 在上述定理的条件下,必有
	 
	 $g_{k+1}^Td^{(j)}=0,\forall{}j\le{k}$

      4. 上述定理表明,对于二次凸函数,若沿一组共轭方向(非零向量)搜索,经有限步迭代必达到极小点.
	 

** 约束极值问题的最优性条件

*** 约束极值问题
    - 定义[p207]
      \begin{eqnarray}
      min&f(x)\ \ x\in{R^n}\\
      s.t.&g_i(x)\ge{0},i=1,\cdots,m\nonumber\\
      &h_j(x)=0,j=1,\cdots,l\nonumber
      \end{eqnarray}
      
      其中, $g_i(x)\ge{0}$ 称为不等式约束, $h_j(x)=0$ 称为等式约束.集合
      
      $S=\{x|g_i(x)\ge{0},i=1,\cdots,m;h_j(x)=0,j=1,\cdots,l\}$
      
      称为可行集或可行域.

*** 可行方向与下降方向
    - 如果 $\bar{x}$ 是 $f(x)$ 在 $S$ 上的局部极小点,则在 $\bar{x}$ 处的可行方向一定不是
      下降方向.

    - 定理[p207]
      考虑问题
      \begin{eqnarray}
      min\ f(x)\\
      s.t.\ x\in{S}\nonumber
      \end{eqnarray}
      
      设 $S$ 是 $R^n$ 中的非空集合, $\bar{x}\in{S}$ , $f(x)$ 在 $\bar{x}$ 处可微.如果 $\bar{x}$ 是局部最优解,
      则 $F_0\cap{D}=\phi$ .其中 $F_0$ 和 $D$ 分别是下降方向集和可行方向集.
      
**** 下降方向
     - 定义[p207]
       设 $f(x)$ 是定义在 $R^n$ 上的实函数, $\bar{x}\in{R^n}$ , $d$ 是非零向量.若存在数 $\delta>0$ ,
       使得对每个 $\lambda\in(0,\delta)$ ,都有
       
       $f(\bar{x}+\lambda{d})<f(\bar{x})$
       
       则称 $d$ 为函数 $f(x)$ 在 $\bar{x}$ 处的下降方向.

     - 如果 $f(x)$ 是可微函数,且 $\nabla{}f(\bar{x})^Td<0$ ,显然 $d$ 为 $f(x)$ 在 $x$ 处的下降方向.
       此时记作
       
       $F_0=\{d\mid{}\nabla{f(\bar{x})}^Td<0\}$
       
**** 可行方向
     - cl(S) 是包含 S 的最小的闭集。

     - 定义[p207]
       设集合 $S\subset{R^n}$ , $\bar{x}\in{cl\ S}$ , $d$ 是非零向量,若存在数 $\delta>0$ ,使得对每一个 
       $\lambda\in(0,\delta)$ ,都有
       
       $\bar{x}+\lambda{d}\in{S}$
       
       则称 $d$ 为集合 $S$ 在 $\bar{x}$ 的可行方向.其中 "$cl$" 表示闭包, $cl\ S$ 即 $S$ 的闭包.

     - 集合 $S$ 在 $\bar{x}$ 处的所有可行方向组成的集合
       
       $D=\{d\mid{}d\ne{0},\bar{x}\in{cl\ S},\exists{\delta}>0,make\ \forall{\lambda}\in(0,\delta),have\ \bar{x}+\lambda{d}\in{S}\}$
       
       称为在 $\bar{x}$ 处的可行方向锥.

*** 不等式约束问题的一阶最优性条件

**** 起作用约束[p208]
     - 考虑非线性规划问题
       \begin{eqnarray}
       min\ f(x)&\\
       s.t.\ g_i(x)\ge0,\ &i=1,\cdots,m\nonumber
       \end{eqnarray}

     - 我们研究在一点处的可行方向时,只需考虑在这一点的起作用约束,那些不起作用的约束可以暂且不管.
       用符号 $I$ 表示起作用约束下标集,即
       
       $I=\{i\mid{}g_i(\bar{x})=0\}$
       
       定义起作用约束后,就能用集合
       
       $G_0=\{d\mid{}\nabla{}g_i(\bar{x})^Td>0,i\in{I}\}$
       
       取代可行方向锥 $D$ .

**** 定理[p209]
     - 设 $\bar{x}\in{S}$ , $f(x)$ 和 $g_i(x)(i\in{I})$ 在 $\bar{x}$ 可微, $g_i(x)(i\notin{I})$ 在
       $\bar{x}$ 连续.如果 $\bar{x}$ 是不等式约束问题的局部最优解,则
       
       $F_0\cap{G_0}=\emptyset$

**** Fritz John 条件[p209]
     - 设 $\bar{x}\in{S},I=\{i\mid{}g_i(\bar{x})=0\},\ f,g_i(i\in{I})$ 在 $\bar{x}$ 处可微,
       $g_i(i\notin{I})$ 在 $\bar{x}$ 处连续,如果 $\bar{x}$ 是不等式约束问题得局部最优解,则存在不全为零的非负数 $w_0$ ,
       $w_i(i\in{I})$ ,使得
       
       $w_0\nabla{}f(\bar{x})-\sum_{i\in{I}}w_i\nabla{}g_i(\bar{x})=0$

**** Kuhn-Tucker 条件[p212]
     - 运用 Fritz John 条件时,可能出现 $w_0=0$ 的情形.这时,Fritz John 条件中实际上不包含目标函数的任何数据,
       只是把起作用约束的梯度组合成零向量.这样的条件,对于问题的解的描述,没有多少价值.
       
     - 如果增加起作用约束的梯度线性无关的约束规格,则给出不等式约束问题得著名的 K-T 条件:

     - Kuhn-Tucker 条件
       考虑不等式约束问题.设 $\bar{x}\in{S},\ f,g_i(i\in{I})$ 在 $\bar{x}$ 处可微, $g_i(i\notin{I})$ 在点 $\bar{x}$ 连续,
       $\{\nabla{}g_i(\bar{x})\mid{}i\in{I}\}$ 线性无关.若 $\bar{x}$ 是局部最优解,则存在非负数 $w_i$ , $i\in{I}$ ,使得
       
       $\nabla{f(\bar{x})}-\sum_{i\in{I}}w_i\nabla{}g_i(\bar{x})=0$

** 惩罚函数法
   - 属于约束最优化方法,基本思想是:借助罚函数把约束问题转化为无约束问题,进而用无约束最优化方法来求解.

*** 外点罚函数法[p394]

**** 罚函数的概念[p394]
*****     - 考虑约束问题
       \begin{eqnarray}
       min\ &f(x)\\
       s.t.\ &g_i(x)\ge{0},\ i=1,\cdots,m\nonumber\\
       &h_j(x)=0,\ j=1,\cdots,l
       \end{eqnarray}
       
       其中, $f(x),g_i(x),h_j(x)$ 是 $R^n$ 上的连续函数.

*****     - 把约束问题转化为无约束问题
       $min\ F(x,\sigma)\stackrel{def}{=}f(x)+\sigma{}P(x)$
       
       其中 $\sigma$ 是很大的正数, $P(x)$ 是连续函数.

*****     - $P(x)$ 具有下列形式:
       $P(x)=\sum_{i=1}^{m}\phi(g_i(x))+\sum_{j=1}^{l}\psi(h_j(x))$
       
       $\phi$ 和 $\psi$ 是满足下列条件的连续函数:
       \begin{eqnarray}
       \phi(y)=0,\ y\ge{0};\nonumber\\
       \phi(y)>0,\ y<0;\nonumber\\
       \psi(y)=0,\ y=0;\nonumber\\
       \psi(y)>0,\ y\ne{0}
       \end{eqnarray}
       
       $\phi$ 和 $\psi$ 的典型取法:
       
       $\phi=[max\{0,-g_i(x)\}]^{\alpha}$
       
       $\psi=\mid{}h_j(x)\mid{}^{\beta}$
       
       其中 $\alpha\ge{1},\beta\ge{1}$ ,均为给定常数,通常取 $\alpha=\beta=2$

***** 性质
      - 根据定义,当 $x$ 为可行点时, $P(x)=0$ ,从而有 $F(x,\sigma)=f(x)$
      - 当 $x$ 不是可行点时,在 $x$ 处, $\sigma{}P(x)$ 是很大的正数,它的存在是对点脱离可行域的一种惩罚,
	其作用是在极小化过程中迫使迭代点靠近可行域.
      - 通常将 $\sigma{P(x)}$ 称为罚项, $\sigma$ 称为罚因子, $F(x,\sigma)$ 称为罚函数
      - 无约束问题的最优解 $\bar{x}_{\sigma}$ 往往不满足原来问题的约束条件,它是从可行域外部趋向 $\bar{x}$ 的,因此 $F(x,\sigma)$
	也称为外点罚函数,相应的最优化方法称为外点罚函数法,简称外点法.

**** 外点罚函数法计算步骤[p398]

***** SUMT (序列无约束极小化方法)[p398]
      - 一般策略是取一个趋向无穷大的严格递增正数列 $\{\sigma_k\}$ ,从某个 $\sigma_1$ 开始,对每个 $k$ ,求解
	$min\ f(x)+\sigma_kP(x)$
	
	从而得到一个极小点的序列 $\{\bar{x}_{\sigma_k}\}$ ,在适当的条件下,这个序列将收敛于约束问题的最优解.

      - 外点罚函数法[p398]
	1) 给定初始点 $x^{(0)}$ ,初始罚因子 $\sigma_1$ ,放大系数 $c>1$ ,允许误差 $\varepsilon>0$ ,
	   置 $k=1$

	2) 以 $x^{(k-1)}$ 为初点,求解无约束问题
	   $min\ f(x)+\sigma_kP(x)$
	   
	   设其极小点为 $x^{(k)}$

	3) 若 $\sigma_kP(x^{(k)})<\varepsilon$ ,则停止计算,得到点 $x^{(k)}$ ;否则,令 $\sigma_{k+1}=c\sigma_k$ ,
	   置 $k=k+1$ ,返回步骤 (2)

**** 收敛性[p398]
     - 引理[p398]
       设 $0<\sigma_k<\sigma_{k+1},x^{(k)}$ 和 $x^{(k+1)}$ 分别为取罚因子 $\sigma_k$ 及 $\sigma_{k+1}$ 时无约束问题的
       全局极小点,则下列各式成立:

       1) $F(x^{(k)},\sigma_k)\le{}F(x^{(k+1)},\sigma_{k+1})$

       2) $P(x^{(k)})\ge{}P(x^{(k+1)})$

       3) $f(x^{(k)})\le{}f(x^{(k+1)})$

     - 引理[p399]
       设 $\bar{x}$ 是有约束问题得最优解,且对任意的 $\sigma_k>0$ ,罚函数 $F(x,\sigma_k)$ 存在全局极小点 $x^{(k)}$ ,
       则对每一个 $k$ ,成立
       
       $f(\bar{x})\ge{}F(x^{(k)},\sigma_k)\ge{}f(x^{(k)})$

     - 定理[p399]
       设约束问题的可行域 $S$ 非空,且存在一个 $\varepsilon>0$ ,使得集合
       
       $S_{\varepsilon}=\{x\mid{}g_i(x)\ge{-\varepsilon},i=1,\cdots,m,\ \mid{h_j(x)}\mid\le{\varepsilon},j=1,\cdots,l\}$
       
       是紧的,又设 $\{\sigma_k\}$ 是趋向无穷大的严格递增正数列,且对每个 $k$ , $min\ f(x)+\sigma_kP(x)$ 
       存在全局最优解 $x^{(k)}$ ,则 $\{x^{(k)}\}$ 存在一个收敛子序列 $\{x^{(k_j)}\}$ ,并且任何这样的收敛子序列的极限都是
       约束问题的最优解.
       
       
